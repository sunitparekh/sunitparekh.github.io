<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sUnit Blog</title>
    <link>//www.sunitparekh.in/</link>
    <description>Recent content on sUnit Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>2020 sunitparekh.in</copyright>
    <lastBuildDate>Fri, 01 May 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="//www.sunitparekh.in/index.xml" rel="self" type="application/rss+xml" />
    
    
    
        <item>
        <title>About Me</title>
        <link>//www.sunitparekh.in/about/</link>
        <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/about/</guid>
        <description>sUnit Blog //www.sunitparekh.in/about/ -&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/sunit.jpeg&#34; alt=&#34;Sunit Parekh&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;application-developer-from-thoughtworks-pune&#34;&gt;Application Developer from ThoughtWorks, Pune&lt;/h2&gt;
&lt;p&gt;I am a polygot Application Developer, currently working at ThoughtWorks Pune. My experience includes using Java, Ruby and Scala to develop complex enterprise applications and large-scale websites. Apart from architecting solutions, I have done coaching on agile practices like TDD, Refactoring, Continuous Integration and Continuous Delivery.&lt;/p&gt;
&lt;p&gt;I am passionate about learning new technologies and using them to solve complex business problems. I have build &lt;strong&gt;&lt;a href=&#34;http://sunitparekh.github.io/data-anonymization/&#34;&gt;Data Anonyization&lt;/a&gt;&lt;/strong&gt; a tool that helps with anonymizing production data to use for performance testing, security testing, debugging production issues and development purposes.&lt;/p&gt;
- //www.sunitparekh.in/about/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Release based 3 branch model for agile software development</title>
        <link>//www.sunitparekh.in/posts/30-three-branching-model/</link>
        <pubDate>Sun, 21 Aug 2016 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/30-three-branching-model/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/30-three-branching-model/ -&lt;p&gt;On large teams it is very important that everyone understands and follow the same branching model/workflow. One of very popular branching workflow is &lt;a href=&#34;http://nvie.com/posts/a-successful-git-branching-model/&#34;&gt;GitFlow&lt;/a&gt;, however with distributed and novice team following GitFlow is difficult. So over a period of time I have been following simple 3 branch model for development which works fine for agile and continuous delivery software development method.&lt;/p&gt;
&lt;h2 id=&#34;3-branch-workflow-model&#34;&gt;3 Branch workflow model&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/xXc3YvzJPD4&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;hr&gt;
&lt;h2 id=&#34;challenges-with-following-gitflow-on-large-distributed-teams&#34;&gt;Challenges with following GitFlow on large distributed teams&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Team to be at advance level of using Git version control with good hold on branching, merging techniques.&lt;/li&gt;
&lt;li&gt;Limited number of downstream environments (DEV, QAT, UAT, &amp;hellip;) it is not possible to deploy all features changes for testing, showcase/demo purpose at a time.&lt;/li&gt;
&lt;li&gt;Refactoring becomes difficult since it creates lot of merge issues across feature branches.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;slides&#34;&gt;Slides&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Slides are available &lt;a href=&#34;https://docs.google.com/presentation/d/117bnmIVoBOLtDqgHSPta2guzlCEBNNyaFA-Oz7dyGaI/edit?usp=sharing&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
- //www.sunitparekh.in/posts/30-three-branching-model/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Distributed Agile - What should be the Sprint duration?</title>
        <link>//www.sunitparekh.in/posts/29-sprint-duration/</link>
        <pubDate>Wed, 17 Aug 2016 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/29-sprint-duration/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/29-sprint-duration/ -&lt;p&gt;&lt;strong&gt;What should be the  Sprint duration?&lt;/strong&gt; this question comes up quite commonly on agile projects and opinions vary from as short as a week to as long as 6 weeks. Decision on an appropriate Sprint length depend on many factors. Few of the factors that I consider while deciding on the Sprint length are as follows, however, each factor adds different dimensions when the team is distributed across time zones.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/29/featured.png&#34; alt=&#34;sprint duration factors&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;decision-making&#34;&gt;Decision Making:&lt;/h2&gt;
&lt;p&gt;In most agile team all decision makers from business to technical people are co-located or available within a working day. Sometimes business and product owners are sitting in different locations and it takes a minimum of two working days to make decisions. And if one of them is on leave, decisions gets further delayed. Faster decision-making drives towards shorter sprint cycles and longer decision making drives towards longer cycles.&lt;/p&gt;
&lt;h2 id=&#34;team-distribution&#34;&gt;Team Distribution:&lt;/h2&gt;
&lt;p&gt;Nowadays it is quite common to have a distributed team. Number of locations includes everyone from business stakeholders, users, product owner, technical stakeholders, developers, testers, infrastructure and release teams. With a  distributed team, there are overheads including prioritisation and planning to tracking and  development to testing and release. The maximum overhead with distributed teams is the communication effort and time to make sure all are on same page and similar expectations. Having a healthy overlap (2 to 4 working hrs) between teams works in favor, however, with time zone differences such as India and US West Coast this becomes particularly impossible. The more the teams are distributed, the longer the sprint cycle become.&lt;/p&gt;
&lt;h2 id=&#34;story-size-e2e-elapsed-time&#34;&gt;Story Size (E2E elapsed time):&lt;/h2&gt;
&lt;p&gt;Every story that is part of the Sprint should be completed end 2 end from low level design to development and testing within the Sprint. A simple rule is  that the largest sized story should fit within a Sprint. E.g. if my largest and most complex story takes 2-3 elapsed days for design,  6-8 elapsed days for development and 3-4 elapsed days for testing, then having a 2 weeks cycle of is NOT ideal. This is a very important aspect to consider if one would like to deliver meaty features to users every sprint. Either figure out creative ways to fit stories within sprint, or, as a last resort, increase the length of your sprint.&lt;/p&gt;
&lt;h2 id=&#34;regression-testing-effort-and-size&#34;&gt;Regression testing effort and size:&lt;/h2&gt;
&lt;p&gt;For frequent releases and continuous delivery, it is very important to have shorter testing cycles. Automation is a key, starting from unit testing till end2end functional testing, performance testing, capacity testing and security testing - everything should be automated in an optimal manner. Shorter the full testing cycle, shorter the Sprint length. Read more about testing automation &lt;a href=&#34;https://www.thoughtworks.com/insights/blog/guidelines-structuring-automated-tests&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;release-sign-off-and-deployment-process&#34;&gt;Release sign-off and deployment process:&lt;/h2&gt;
&lt;p&gt;This factor is very important in deciding the duration of the Sprint cycle as well. In large organisations regular releases are scheduled during weekends (off hours) and done by independent teams (release management and infrastructure team). Also the process of reserving the release slot needs multiple level of approval with all the details and testing evidences attached. Now all these processes with these teams distributed across time zones makes releases more complicated and lengthy even though we have a fully automated deployment using CI/CD infrastructure in place. So effort and time for the release signoff and deployment process directly impacts the Sprint duration. Read more about CI/CD &lt;a href=&#34;http://www.slideshare.net/gsluthra/recipes-for-continuous-delivery&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;agile-maturity-of-team&#34;&gt;Agile maturity of team:&lt;/h2&gt;
&lt;p&gt;When the team is new to agile practices, initial time gets spent in learning agile practices such as sprint prioritisation and planning, automated testing, continuous integration, automated deployment, retrospectives, etc. While learning agile practices if the team tries to follow shorter sprint cycle, then the team is going to find it difficult to follow and learn agile practices effectively, as it will be busy doing sprint ceremonies. So sometimes it is recommended that you start with longer spring cycle and as the team maturity increases, shorten the sprint duration in a planned manner.&lt;/p&gt;
&lt;h2 id=&#34;real-life-project-example&#34;&gt;Real-life project example&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;On one of my project initially after project inception with distributed team in 4 location (US West Coast, Brussels, London, India) we started with 4 week sprint. Our go-live was after 8 sprints (almost 7 months) and after that we moved to 3 week sprint and every 2 sprint release to production. We kept release every 2 sprint till we smooth out overall processes with multiple team having minimum overheads. After six months team re-visited release duration, and moved to releasing to production every sprint i.e. 3 weeks. However sprint duration was kept at 3 week only so release has some meaty features in it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The above factors help in defining the Sprint cycle and help deliver sizeable number of features to production considering distributed team overheads. Balancing pure development effort vs. all other non-development effort is the key here, otherwise the team will deliver lesser features against effort spent on non-development activities.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In my view, for co-located teams or distributed teams with healthy overlap time and at intermediate level of agile engineering practices I would suggest 2 week sprint duration. And for highly distributed team which is mostly new to Agile (and CD) practices, I recommend 4 weeks of initial Sprint duration.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Philosophy of &amp;ldquo;shorter sprints are better&amp;rdquo; is not always right. Sometimes with shorter sprints and significant non-development effort, team&amp;rsquo;s stress level increases while stakeholder sees less deliverable, watch-out for such cases.&lt;/p&gt;
- //www.sunitparekh.in/posts/29-sprint-duration/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Ownership model for distributed team</title>
        <link>//www.sunitparekh.in/posts/28-ownership-model/</link>
        <pubDate>Wed, 13 Apr 2016 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/28-ownership-model/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/28-ownership-model/ -&lt;p&gt;Setting up distributed team is very common in new world of software development. However, it is equally important that each team operates in complete autonomy and there is a need for teams to be independent, taking ownership and deliver. However, everyone has different views and understanding of ownership. I would like to take this opportunity to explain my view on different aspects of ownership which can help stakeholders and team in having common understanding of expectations and help deliver with ownership and accountability.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start with first understanding different aspects of ownership. Software development ownership can be viewed as three types &lt;strong&gt;technical&lt;/strong&gt;, &lt;strong&gt;solution&lt;/strong&gt; and &lt;strong&gt;business&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;3-types-of-ownership&#34;&gt;3 Types of ownership&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/28/3-pillers.png&#34; alt=&#34;3 Types of Ownership for Distributed Teams&#34; title=&#34;3 Types of Ownership for Distributed Teams&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Technical ownership&lt;/strong&gt; means delivering quality product (code) by following engineering practices such as unit testing, refactoring, continuous integration, automated build and deployment etc. with full autonomy. Technical ownership also includes owning technical decisions at low level including following design patterns, cleaner API development for software development.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;In &lt;em&gt;technical ownership&lt;/em&gt; delivering quality code could be the first step and reaching continuous delivery with automated build and deployment could be the higher level of maturity.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Solution ownership&lt;/strong&gt; is about providing solutions to solve business problems. e.g. a) for retail website building recommendation engine based on what a user is searching for, b) to achieve mobile first build UX/UI with responsive web design approach. Solution also involves how we can deliver the feature e.g. define MVP and roll out as first cut to end users and with each release keep enhancing the feature as needed.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;For &lt;em&gt;solution ownership&lt;/em&gt; deciding appropriate technology to solve the problem (using ElasticSearch for free text search) is first and making tech stack, frameworks and architecture decisions and delivering it (Java vs .NET, microservice architecture, NoSQL datastore), is higher level of maturity&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Business ownership&lt;/strong&gt; involves working closely with business in defining business needs and helps in building digital solution to solve the problem. e.g. on retail website defining the reward scheme and to promote mobile applications give more reward. Plays partner role with business owners and gets involved in defining long term business strategies as well.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;The most tricky one is &lt;em&gt;business ownership&lt;/em&gt; where it is very difficult to define what is expected. One way to detect this maybe how early do you get involved in the discussion. Do you get to define the requirement, and identify the problem or does get involved only after the requirement and likely solution have been decided.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;distributed-team-models-based-on-ownership&#34;&gt;Distributed team models based on ownership&lt;/h3&gt;
&lt;p&gt;Lets take example of retail business and see two classical distributed team models,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Vertical (Feature) based full ownership team model&lt;/strong&gt;: setup teams with all roles to take up full ownership of feature. E.g. Product Catalog team, Order management team, Shipping management team. Each team has full autonomy to operate from business decision to technology choices made in respective area.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Horizontal (Competency) based ownership team model&lt;/strong&gt;: Front end web team, Mobile team, API team, Operations team&amp;hellip; each team has specific role to play and take ownership of each area specifically technical and solution ownership.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/28/featured.png&#34; alt=&#34;Horizontal/Competency based Distributed Team Model&#34; title=&#34;Horizontal/Competency based Distributed Team Model&#34;&gt;&lt;/p&gt;
&lt;p&gt;Feature based full ownership team is what I think better for ownership and accountability. However, I have see more horizontal/competency based ownership model in practice. In my view having clarify with all members about the team model is more important and choose whatever works for you.&lt;/p&gt;
&lt;h3 id=&#34;type-of-ownership-and-roles&#34;&gt;Type of ownership and roles&lt;/h3&gt;
&lt;p&gt;It is important to understand, what is expected from the team and capability &amp;amp; strength of each team? Above becomes less relevant when team is co-located since everyone is within walk and talk reach. And it becomes more relevant in distributed team, each team requires specific roles to achieve each type of ownership.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Developers, QAs and BAs can help achieve Technical ownership.&lt;/li&gt;
&lt;li&gt;We need tech leadership to provide architecture solution along with supporting roles like project management for execution and planning.&lt;/li&gt;
&lt;li&gt;Similarly we need Product Owners and Senior BAs to achieve Business ownership.&lt;/li&gt;
&lt;/ol&gt;
- //www.sunitparekh.in/posts/28-ownership-model/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Testing emails with Fake SMTP service</title>
        <link>//www.sunitparekh.in/posts/27-testing-emails/</link>
        <pubDate>Sat, 17 Oct 2015 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/27-testing-emails/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/27-testing-emails/ -&lt;p&gt;Testing is key activity of every software development projects. However testing certain features is not easy and need special support functions. One of such functionality is email testing. In this article I introduce few tools that I used in my projects for achieving email testing easily without any side effects.&lt;/p&gt;
&lt;p&gt;To test emails effectively we end up using real email addresses, which leads to cluttering mailbox with unwanted emails. For testing different scenarios we need multiple email address, and testing becomes more difficult when it requires checking mailbox of other users. Also we never want to send emails to real users, otherwise they gets confused with test emails and real emails. Also we do not want to make any code modification for testing emails, this leads to code maintenance issues.&lt;/p&gt;
&lt;p&gt;To overcome above problems, what we need is, &lt;strong&gt;Fake SMTP server (Email Service) which acts as outgoing server, however, it never delivers email message to users and provides a user interface to check and verify all outgoing emails.&lt;/strong&gt; In short application sends email to users however it never goes out of SMTP server.&lt;/p&gt;
&lt;p&gt;We need Fake SMTP server for following different scenarios,&lt;/p&gt;
&lt;h2 id=&#34;1-unit-testing&#34;&gt;1. Unit Testing&lt;/h2&gt;
&lt;p&gt;Embedded version with Assertion support for Unit Testing, so emails can be verified using asserts in unit tests. &lt;a href=&#34;http://quintanasoft.com/dumbster/&#34;&gt;Dumbster&lt;/a&gt; is handy library here. Some frameworks like &lt;a href=&#34;http://guides.rubyonrails.org/testing.html#testing-your-mailers&#34;&gt;Rails&lt;/a&gt; has inbuilt support for unit testing emails.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;TestEmail&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;@Test&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testSend&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        SimpleSmtpServer server &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SimpleSmtpServer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;start&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;

        sendMessage&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Subject&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Test Body&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;abc@example.com&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;);&lt;/span&gt;

        server&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;stop&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;

        assertThat&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;server&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;getReceivedEmailSize&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(),&lt;/span&gt;equalTo&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1&lt;span style=&#34;color:#f92672&#34;&gt;));&lt;/span&gt;

        Iterator emails &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; server&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;getReceivedEmail&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;
        SmtpMessage email &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;SmtpMessage&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;emails&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;next&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;();&lt;/span&gt;

        assertThat&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;email&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;getHeaderValue&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Subject&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;),&lt;/span&gt;equalTo&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Subject&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;));&lt;/span&gt;
        assertThat&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;email&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;getHeaderValue&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;To&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;),&lt;/span&gt;equalTo&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;abc@example.com&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;));&lt;/span&gt;
        assertThat&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;email&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;getBody&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(),&lt;/span&gt;equalTo&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Test Body&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;));&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;2-local-developer-box-testing&#34;&gt;2. Local Developer Box Testing&lt;/h2&gt;
&lt;p&gt;Local SMTP service with standalone application for developer box testing. So after development developers/testers can verify emails functionality locally.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://nilhcem.github.io/FakeSMTP/&#34;&gt;&lt;strong&gt;FakeSMTP&lt;/strong&gt;&lt;/a&gt; No installation required. Just run a simple JAR file. Works on any platform.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jaben/papercut&#34;&gt;&lt;strong&gt;Papercut&lt;/strong&gt;&lt;/a&gt; Windows only solution. Better UI than FakeSMTP but requires installation&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;3-hosted-service&#34;&gt;3. Hosted Service&lt;/h2&gt;
&lt;p&gt;Hosted service with Web UI for Non-Production (QA, UAT, Staging) environments, which helps multiple tester to verify email functionality.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://mailcatcher.me/&#34;&gt;&lt;strong&gt;Mailcatcher&lt;/strong&gt;&lt;/a&gt; It has a web view which allows viewing messages from anywhere, ruby application that can runs independently.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mailtrap.io&#34;&gt;&lt;strong&gt;Mailtrap.io&lt;/strong&gt;&lt;/a&gt; Cloud based SaaS solution, very sophisticated but paid.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/27/featured.png&#34; alt=&#34;mailcatcher.me&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Using tools and techniques which are applicable for different stages of testing, we can effectively test all email scenarios without delivering emails to real users. Above solutions doesn&amp;rsquo;t require any change in production code for testing, just needs different configuration of SMTP server.&lt;/p&gt;
&lt;p&gt;Happy Testing !!!&lt;/p&gt;
- //www.sunitparekh.in/posts/27-testing-emails/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Collaboration Techniques for Large Distributed Agile Projects</title>
        <link>//www.sunitparekh.in/posts/26-collaboration-techniques/</link>
        <pubDate>Fri, 20 Feb 2015 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/26-collaboration-techniques/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/26-collaboration-techniques/ -&lt;h2 id=&#34;article-is-published-on-thoughtworks-insights-herehttpswwwthoughtworkscominsightsblogcollaboration-techniques-large-distributed-agile-projects&#34;&gt;Article is published on ThoughtWorks Insights &lt;a href=&#34;https://www.thoughtworks.com/insights/blog/collaboration-techniques-large-distributed-agile-projects&#34;&gt;here&lt;/a&gt;..&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.thoughtworks.com/insights/blog/collaboration-techniques-large-distributed-agile-projects&#34;&gt;https://www.thoughtworks.com/insights/blog/collaboration-techniques-large-distributed-agile-projects&lt;/a&gt;&lt;/p&gt;
- //www.sunitparekh.in/posts/26-collaboration-techniques/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Story Mapping, Visual Way of Building Product Backlog</title>
        <link>//www.sunitparekh.in/posts/25-story-mapping/</link>
        <pubDate>Tue, 13 Jan 2015 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/25-story-mapping/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/25-story-mapping/ -&lt;h2 id=&#34;article-is-published-on-thoughtworks-insights-herehttpwwwthoughtworkscominsightsblogstory-mapping-visual-way-building-product-backlog&#34;&gt;Article is published on ThoughtWorks Insights &lt;a href=&#34;http://www.thoughtworks.com/insights/blog/story-mapping-visual-way-building-product-backlog&#34;&gt;here&lt;/a&gt;..&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.thoughtworks.com/insights/blog/story-mapping-visual-way-building-product-backlog&#34;&gt;http://www.thoughtworks.com/insights/blog/story-mapping-visual-way-building-product-backlog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/25/featured.jpg&#34; alt=&#34;Story Map&#34;&gt;&lt;/p&gt;
- //www.sunitparekh.in/posts/25-story-mapping/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>How to begin with Agile and Continuous Delivery on Legacy Projects?</title>
        <link>//www.sunitparekh.in/posts/24-legacy-projects/</link>
        <pubDate>Fri, 31 Oct 2014 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/24-legacy-projects/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/24-legacy-projects/ -&lt;p&gt;In my interactions with people, I hear &amp;ldquo;Agile and Continuous Delivery works for new green field projects, but we have legacy project. We don&amp;rsquo;t know where to start or we can&amp;rsquo;t do agile and continuous delivery on our project&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Most of the time legacy projects are facing typical issues like fragile codebase, too much technical debt, old libraries &amp;amp; frameworks. Which resulting into long development and testing cycles. To solve these problems, team decides to follow Agile practices. Following agile practices requires specialized skills like Continuous Integration, Test Driven Development, Refactoring and Evolutionary Design&amp;hellip; and difficulty is where to start, there are so many agile engineering practices. Should we start Big Bang, stop all development until we have CI, Automated Tests, &amp;hellip; everything in place? My answer is No Big Bang.&lt;/p&gt;
&lt;p&gt;Here is step by step approach that worked for me to move towards CD with agile practices. Remember this is a journey and can take upto months or years to get results, based on size of the project, so have patience.&lt;/p&gt;
&lt;h2 id=&#34;step-1-automated-build-and-deployment&#34;&gt;Step 1: Automated build and deployment&lt;/h2&gt;
&lt;p&gt;On most of the legacy projects I have seen, taking build and performing deployment is quite long process. One of the main reason for long cycle is, build and deployment steps are manual, resulting into long downtime for systems (environments) during deployment. If we notice all the steps we do for building artifacts and performing deployment are repetitive and can be automated using scripts. In case of product we can have automated upgrades for client with proper distribution channel.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools and techniques for automated build&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Packaging application in native format using tools like &lt;a href=&#34;https://github.com/jordansissel/fpm&#34;&gt;FPM&lt;/a&gt; to build RPM, DEB packages to deploy application in native way. For products this approach is ideal and we can leverage system default package manager for automated upgrade. And this is quite common in applications distributions like Apache HTTP Server, JDK etc.&lt;/li&gt;
&lt;li&gt;Use Continuous Integration servers like &lt;a href=&#34;http://www.go.cd/&#34;&gt;Go&lt;/a&gt; to build artifacts and trigger deployment.&lt;/li&gt;
&lt;li&gt;Use &lt;a href=&#34;http://www.getchef.com/chef/&#34;&gt;Chef&lt;/a&gt; to provision servers and deploy applications triggered via downstream pipelines in CI server.&lt;/li&gt;
&lt;li&gt;Use &lt;a href=&#34;http://flywaydb.org/&#34;&gt;Flyway&lt;/a&gt; or &lt;a href=&#34;http://www.liquibase.org/&#34;&gt;Liquibase&lt;/a&gt; for running database migrations in incremental way.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/24/simple-pipeline.svg&#34; alt=&#34;simple deployment pipeline&#34;&gt;&lt;/p&gt;
&lt;p&gt;Next question comes in mind is, what should be the branching strategy? I recommend following 3 active branch strategy.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Master development branch&lt;/strong&gt;, used continuously for active development&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Release Candidate branch&lt;/strong&gt;, is very short lived branch, created as release candidate for production and cut from master. Once deployed to production this becomes the &lt;em&gt;Production branch&lt;/em&gt; This is also known as &lt;strong&gt;beta&lt;/strong&gt; branch.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Production branch&lt;/strong&gt;, used for defect and emergency fixes (hotfix)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/24/3-branch-pipeline.svg&#34; alt=&#34;3 branch deployment pipeline&#34;&gt;&lt;/p&gt;
&lt;p&gt;Doing automated deployment enables us to deploy any build at will even for small bug fix. This enables QA to get latest code for testing anytime as soon as it is checked in by developers. At this step we are still doing manual testing.
{: .clear}&lt;/p&gt;
&lt;h2 id=&#34;step-2-automated-sanity-test-suite&#34;&gt;Step 2: Automated sanity test suite&lt;/h2&gt;
&lt;p&gt;Building full automation suite to get good coverage for CD is long way to go. My suggestion here is to start small, identify blockers or critical end user scenarios and write automated tests just for those. Blocker means if something fails then end user is unable to use application and critical for business to continue. e.g. in retail website, credit card payment not working in purchase workflow. Lets call this test suite as sanity. Remember to keep this as small as possible, I would say this test suite should run in 10 min max.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/24/automated-sanity-test.svg&#34; alt=&#34;automated sanity test&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once the &amp;lsquo;Sanity automated tests&amp;rsquo; are ready, lets put them to run on every check-in using CI setup done before. This provides safety net against critical paths for every check-in done by developer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools and techniques for automated build&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Perform headless website testing using &lt;a href=&#34;http://phantomjs.org/headless-testing.html&#34;&gt;PhantomJS&lt;/a&gt; in combination with &lt;a href=&#34;http://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt; and &lt;a href=&#34;https://github.com/airportyh/testem&#34;&gt;Testem&lt;/a&gt;. Other alternatives are &lt;a href=&#34;http://docs.seleniumhq.org/&#34;&gt;Selenium&lt;/a&gt; and &lt;a href=&#34;http://sahi.co.in/sahi-open-source/&#34;&gt;Sahi&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Same Sanity test suite can be run against all environments with different configurations and parameters. This helps in verifying and building confidence in our builds and deployments in each environment.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Evolve automated sanity test suite to achieve acceptance test suite with more End-2-End type of tests. However, please make sure you follow &lt;a href=&#34;http://martinfowler.com/bliki/TestPyramid.html&#34;&gt;Test Pyramid&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-3-development-with-automated-unit-tests-and-refactoring&#34;&gt;Step 3: Development with automated unit tests and refactoring&lt;/h2&gt;
&lt;p&gt;Now the tough one. Big bang unit testing and refactoring is &lt;em&gt;big NO&lt;/em&gt;. You need to be most careful in this part of CD adoption. First step is to define single &lt;a href=&#34;&#34;&gt;Automated Tests Strategy&lt;/a&gt;. Make sure everyone understands &lt;a href=&#34;http://martinfowler.com/bliki/TestPyramid.html&#34;&gt;Test Pyramid&lt;/a&gt; and follows principle of write more unit tests and less acceptance tests. Avoid repeating same tests in different test suites. There is one and only one test stratergy across team, do not fall into trap of different strategy for development team and testing team, remember ONE team.&lt;/p&gt;
&lt;p&gt;I recommend baby steps again here, do refactoring and write unit tests only for features which are under development and touched for enhancement. Do not try to cover non-touched code. In case of Registration feature not changing, do not write unit tests or refactor code related to registration feature.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/24/automated-unit-test.svg&#34; alt=&#34;automated unit test&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Do progressive refactoring and test coverage for code under heavy development, do just enough for others. In short invest more in changing codebase and less in dead code.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;Steps for development,&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write unit test for existing functionality, provide safety net before you make the enhancements. Sometime code is not in a shape of writing unit tests and without refactoring you won&amp;rsquo;t be able to write unit tests. In such cases just do enough refactoring which enables you to write unit tests&lt;/li&gt;
&lt;li&gt;Once you have safety net of automated tests, do heavy refactoring if needed&lt;/li&gt;
&lt;li&gt;Now make enhancements either by following test first or test last approach.&lt;/li&gt;
&lt;li&gt;If needed, do refactoring of the code you just wrote before you call it done.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Watch Martin Flower&amp;rsquo;s &lt;a href=&#34;https://www.youtube.com/watch?v=vqEg37e4Mkw&#34;&gt;Workflow of Refactoring&lt;/a&gt; to learn more.&lt;/p&gt;
&lt;h3 id=&#34;test-last-to-test-first-journey&#34;&gt;Test last to test first journey&lt;/h3&gt;
&lt;p&gt;Lots of time I realise that team is not familiar with the xUnit frameworks and not written any unit tests in past. Have patience, give them space to learn how to write effective unit test, learn good practices and patterns in unit testing. Let them start with test last and slowly move them towards test first journey. Since we are looking at legacy project here we are doing test last anyways. Even if you are following test last, do one change to code and write test, do not wait for everything to finish and then write all tests.&lt;/p&gt;
&lt;h3 id=&#34;three-levels-of-refactoring&#34;&gt;Three levels of refactoring&lt;/h3&gt;
&lt;h4 id=&#34;code-level-refactoring&#34;&gt;Code level refactoring&lt;/h4&gt;
&lt;p&gt;This is first level of refactoring that each and every team member should do ruthlessly. Such as better naming, smaller methods, &amp;hellip; etc&lt;/p&gt;
&lt;h4 id=&#34;design-level-refactoring&#34;&gt;Design level refactoring&lt;/h4&gt;
&lt;p&gt;Team should change design within codebase to apply design patterns wherever necessary to represent code in better way which allows to make future enhancements easily. like removing large if/else and switch/case chain to appropriate design pattern. Make sure we share such refactoring with all developers to have knowledge spread across and learning by examples.&lt;/p&gt;
&lt;h4 id=&#34;architecture-level-refactoring&#34;&gt;Architecture level refactoring&lt;/h4&gt;
&lt;p&gt;Most of the time team ask me, Code and Design level refactoring we are able to do but we find it difficult to go for architecture level refactoring. And this is the most important refactoring to break the ice of legacy code. Most of the time legacy codebase is monolithic in nature and would like to move towards service oriented architecture. How to do it? You can&amp;rsquo;t go back to business and say we are stopping all other development and no release for next 3 months since we are doing architecture refactoring. Here is my way for approaching such refactoring,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Build services as method calls using design level refactoring&lt;/li&gt;
&lt;li&gt;Move method calls to services, however, this services coded and deployed in same monolithic way, make localhost calls&lt;/li&gt;
&lt;li&gt;Move services to separate codebase, but deploy in same monolithic way, make localhost calls&lt;/li&gt;
&lt;li&gt;Move service as separate independent deployment, but deploy on same box, make localhost calls&lt;/li&gt;
&lt;li&gt;Make service totally independent as you would liked it to be, make remote calls&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Above steps can take weeks or months based on the complexity and size. My guideline is to divide into steps that you could complete within one iteration, so that you keep it green and always running.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Above steps can be done simultaneously without any restrictions. This is just a guideline and feel free to try different approaches that works for you and your team.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;support-needed-during-cd-journey&#34;&gt;Support needed during CD journey&lt;/h2&gt;
&lt;p&gt;During the agile adoption journey it is important that team gets required support in terms of,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Team needs necessary initial training and coaching on Agile practices like Continuous Integration, Test Driven Development, Refactoring and Evolutionary Design&amp;hellip;&lt;/li&gt;
&lt;li&gt;Have a coach, internal or external, who mentors team on Agile adoption journey. It is important that someone constantly looking at how are team is progressing on CD journey? Is team getting benefits? Is team getting enough support to adopt new way of development?&lt;/li&gt;
&lt;li&gt;All stakeholder needs to understand that during this journey initially when team is learning, refactoring &amp;amp; building automated test suites, it might take little longer to deliver. However after sometime trend should shift and start showing benefits with quicker &amp;amp; quality deliveries.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Run regular retrospective on Agile adoption and CD progress as health check.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Please share your experience with Agile adoption on legacy project and challenges faced using comments.&lt;/p&gt;
- //www.sunitparekh.in/posts/24-legacy-projects/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Building a Two-Stack CMS for a global product catalog</title>
        <link>//www.sunitparekh.in/posts/23-two-stack-cms/</link>
        <pubDate>Mon, 06 Oct 2014 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/23-two-stack-cms/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/23-two-stack-cms/ -&lt;h2 id=&#34;article-is-published-on-martinfowlercom-as-infodeck-herehttpmartinfowlercomarticlestwo-stack-cms&#34;&gt;Article is published on MartinFowler.com as InfoDeck &lt;a href=&#34;http://martinfowler.com/articles/two-stack-cms/&#34;&gt;here&lt;/a&gt;..&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://martinfowler.com/articles/two-stack-cms/&#34;&gt;http://martinfowler.com/articles/two-stack-cms/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/23/two-stack-cms.svg&#34; alt=&#34;Two Stack CMS&#34;&gt;&lt;/p&gt;
- //www.sunitparekh.in/posts/23-two-stack-cms/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Use structured logging for log search and analytics</title>
        <link>//www.sunitparekh.in/posts/22-structured-logging/</link>
        <pubDate>Sat, 06 Sep 2014 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/22-structured-logging/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/22-structured-logging/ -&lt;p&gt;Logging is followed in almost every project. However, most of the time we end up using logs only for debugging and auditing purpose. Since past few projects we have been exploring more opportunities for leveraging logs for purposes like application metrics collection, reporting, monitoring and alerting. And during this, I learnt about structured logging and how it enables us to achieve lot more using logs.&lt;/p&gt;
&lt;p&gt;Lets first look at what we need to follow while logging to achieve structured logging.&lt;/p&gt;
&lt;h2 id=&#34;what-is-structured-logging&#34;&gt;What is structured logging?&lt;/h2&gt;
&lt;p&gt;Not only log level is important, but what we log &amp;amp; how we log also matters. Lets look at the default log message format,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-log&#34; data-lang=&#34;log&#34;&gt;127.0.0.1 [2014-07-22T18:12:27.200+0530] &amp;quot;GET /api/modules/doc_id/navigation HTTP/1.1&amp;quot; 200 476
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Above message is interpreted well by humans since we know, &lt;code&gt;120.0.0.1&lt;/code&gt; is IP, &lt;code&gt;2014-07-22T18:12:27.200+0530&lt;/code&gt; is timestamp, &lt;code&gt;GET&lt;/code&gt; is request methods, &lt;code&gt;200&lt;/code&gt; is response status and &lt;code&gt;476&lt;/code&gt; is server response time. And such interpretation is required for each message logging.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s provide structure to the above log message,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-log&#34; data-lang=&#34;log&#34;&gt;ip=&amp;quot;127.0.0.1&amp;quot; timestamp=&amp;quot;2014-07-22T18:12:27.200+0530&amp;quot; method=GET
url=&amp;quot;/api/modules/doc_id/navigation&amp;quot; protocol=HTTP/1.1 status=200 responseTime=476
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Above structured message is self explanatory and easy to parse and index by system. This technique of &lt;code&gt;key=value&lt;/code&gt; style logging is also known as logging with context. Using above log message keys we can find all slow pages, by querying logs with &lt;code&gt;status = 200&lt;/code&gt; and &lt;code&gt;responseTime &amp;gt; 2000&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now lets take some examples of structured logs to understand it usage better.&lt;/p&gt;
&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;
&lt;h4 id=&#34;background-job-logs&#34;&gt;Background job logs&lt;/h4&gt;
&lt;p&gt;Most of the application now days have have background jobs running at regular interval. With following structured logging for each jobs,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-log&#34; data-lang=&#34;log&#34;&gt;timestamp=&amp;quot;2014-07-22T18:12:27.200+0530&amp;quot; host=server20  tag=jobserver jobName=image_upload
jobStartTime=&amp;quot;2014-07-22T18:10:00.100+0530&amp;quot; jobEndTime=&amp;quot;2014-07-22T18:12:27.100+0530&amp;quot;
jobExecutionTime=9840 jobStatus=success noOfImageUploaded=125
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;following can be achieved,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get alert message when jobStatus is failure, we do&lt;/li&gt;
&lt;li&gt;Monitor average job execution time and we have setup for each job if it reaches more than average sends alert.&lt;/li&gt;
&lt;li&gt;Monitoring average response time also helps in tuning the frequency of the job runs.&lt;/li&gt;
&lt;li&gt;To analyze random failure or slowness in jobs, information in log is really useful to find if it is failing on specific hosts or at specific time or when run in parallel with any other jobs or no of items are too many to process etc.&lt;/li&gt;
&lt;li&gt;Using more meta info like noOfImageUpload and jobExecutionTime we can calculate average time for each image upload.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;distributed-correlated-logs&#34;&gt;Distributed correlated logs&lt;/h4&gt;
&lt;p&gt;With distributed and microservice architecture, it is quite natural to have logs spread across systems. With structure logs and using common transaction id shared across systems, we can correlate logs and turn logs into information used for debugging, auditing, reporting and monitoring.&lt;/p&gt;
&lt;p&gt;Lets take the example of order request after successful payment.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-log&#34; data-lang=&#34;log&#34;&gt;timestamp=&amp;quot;2014-07-22T18:12:27.100+0530&amp;quot; host=server01 tag=webServer
transactionId=458748939 cientIP=83.84.85.86 sessionId=123456789
message=&amp;quot;Order confirmation request received&amp;quot;

timestamp=&amp;quot;2014-07-22T18:12:27.200+0530&amp;quot; host=server03 tag=orderService
transactionId=458748939 message=&amp;quot;Order created&amp;quot;
orderAmount=550

timestamp=&amp;quot;2014-07-22T18:12:27.250+0530&amp;quot; host=server03 tag=inventoryService
transactionId=458748939 message=&amp;quot;Online inventory updated&amp;quot;

timestamp=&amp;quot;2014-07-22T18:12:27.300+0530&amp;quot; host=server07 tag=paymentService
transactionId=458748939 message=&amp;quot;Payment details stored against order.&amp;quot;
paymentMode=CreditCard

timestamp=&amp;quot;2014-07-22T18:12:27.350+0530&amp;quot; host=server05  tag=couponService
transactionId=458748939 message=&amp;quot;Redeem coupon ABCDE marked for user.&amp;quot;
couponType=REWARD couponCode=ABCDE

timestamp=&amp;quot;2014-07-22T18:12:27.400+0530&amp;quot; host=server01 tag=webServer
transactionId=458748939 message=&amp;quot;Request completed&amp;quot;

timestamp=&amp;quot;2014-07-22T18:12:28.500+0530&amp;quot; host=server06  tag=emailService
transactionId=458748939 message=&amp;quot;Order email sent&amp;quot;

timestamp=&amp;quot;2014-07-22T18:12:27.450+0530&amp;quot; host=server05  tag=rewardService
transactionId=458748939 message=&amp;quot;Reward points updated.&amp;quot;

timestamp=&amp;quot;2014-07-22T18:15:00.100+0530&amp;quot; host=server25  tag=shippingService
transactionId=458748939 message=&amp;quot;Order received by shipment system.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;with above messages we can,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We are better equipped with debugging issues across systems including async steps of the transaction. Using transactionId we can connect logs and findout client/user specific details and track incident.  e.g. track couponCode used by user with connecting logs from couponService to webServer&lt;/li&gt;
&lt;li&gt;Using paymentMode, we can learn more about what kind of payment modes are preferred by customers.&lt;/li&gt;
&lt;li&gt;Calculate average response time in processing order request.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Leverage apache &lt;code&gt;mod_unique_id&lt;/code&gt; module to generate transaction id at web server and later share it with other services by passing it in request headers.&lt;/p&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.splunk.com/&#34;&gt;Splunk&lt;/a&gt;, is best in class, commercial product. We are using it in production for large system generating more than 100GB of logs per day. Splunk would be my personal recommendation as well. Lets take example and learn more about using Splunk.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lets find 404s on website using Splunk&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/22/splunk-query.png&#34; alt=&#34;splunk query for finding 404&#34;&gt;&lt;/p&gt;
&lt;p&gt;Query: &lt;code&gt;tag=production sourcetype=nginx-access GET 404 | rex &amp;quot;\&amp;quot;GET (?&amp;lt;url&amp;gt;\S*) &amp;quot; | stats count by url | sort -count | head 20&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Lets understand query in detail. Splunk support &lt;a href=&#34;http://martinfowler.com/articles/collection-pipeline/&#34;&gt;unix style pipes in query&lt;/a&gt;, so you could pass output of one command to another and build on. In above example we used 5 different commands,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;tag=production&lt;/code&gt; and &lt;code&gt;sourcetype=nginx-access&lt;/code&gt; with &lt;code&gt;GET 404&lt;/code&gt; returns all 404 log statements from all productions servers and source file name nginx-access&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rex &amp;quot;\&amp;quot;GET (?&amp;lt;url&amp;gt;\S*) &amp;quot;&lt;/code&gt; extract URL from the log using reg-ex&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stats count&lt;/code&gt; by url group and count by url&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sort -count&lt;/code&gt; sort in descending order on count&lt;/li&gt;
&lt;li&gt;&lt;code&gt;head 20&lt;/code&gt; take first 20 from the result set&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://logentries.com/&#34;&gt;LogEntries&lt;/a&gt; is another feature rich SaaS solution on cloud. Other options are &lt;a href=&#34;https://www.loggly.com/&#34;&gt;Loogly&lt;/a&gt;, &lt;a href=&#34;https://papertrailapp.com/&#34;&gt;PaperTrail&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.elasticsearch.org/overview/logstash/&#34;&gt;LogStash&lt;/a&gt; + &lt;a href=&#34;http://www.elasticsearch.org/overview/elasticsearch/&#34;&gt;Elasticsearch&lt;/a&gt; + &lt;a href=&#34;http://www.elasticsearch.org/overview/kibana/&#34;&gt;Kibana&lt;/a&gt; combination is best open-source one in this space.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://graylog2.org/&#34;&gt;GrayLog2&lt;/a&gt;, open-source log analytics solutions. Used with syslog to aggregate logs.&lt;/p&gt;
&lt;p&gt;Even though structured logging is quite useful on individual system. However until we have logs from all the system collected and indexed together, power of structured logging is under utilized. So lets look at what are different ways we can aggregate logs from multiple systems.&lt;/p&gt;
&lt;h2 id=&#34;how-to-aggregate-logs&#34;&gt;How to aggregate logs?&lt;/h2&gt;
&lt;p&gt;There are multiple approaches available for log aggregation.&lt;/p&gt;
&lt;h4 id=&#34;log-file-replication&#34;&gt;Log File Replication&lt;/h4&gt;
&lt;p&gt;Simplest one is, continue logging to file system on application server and set up an independent process to monitor files and send logs to central log server every &amp;lsquo;n&amp;rsquo; milliseconds.&lt;/p&gt;
&lt;h4 id=&#34;syslog&#34;&gt;Syslog&lt;/h4&gt;
&lt;p&gt;To achieve real time monitoring and alerting we can use syslog approach, directly feeding logs to a central log server. Syslog is available by default on most of the linux machines. &lt;a href=&#34;http://www.rsyslog.com/&#34;&gt;rsyslog&lt;/a&gt; or &lt;a href=&#34;http://www.balabit.com/network-security/syslog-ng/opensource-logging-system/&#34;&gt;syslog-ng&lt;/a&gt; are two popular syslog implementations.&lt;/p&gt;
&lt;h4 id=&#34;agents&#34;&gt;Agents&lt;/h4&gt;
&lt;p&gt;Most of the products in this space provide their own agents, which runs on client and sends logs real-time to central log server. e.g. &lt;a href=&#34;http://wiki.splunk.com/Community:Getting_data_into_Splunk&#34;&gt;Splunk&lt;/a&gt;, &lt;a href=&#34;https://logentries.com/doc/forwarders/&#34;&gt;LogEntries&lt;/a&gt; etc. There are specific tools available just for aggregation purposes like &lt;a href=&#34;http://flume.apache.org/&#34;&gt;Apache Flume&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/22/centralised-logging.svg&#34; alt=&#34;centralised aggregated logs&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In distributed systems it is important that we have realtime log aggregation setup. And it is equally important that time on all application servers is in sync. Since a millisecond differences can have unordered logs and leads to confusion and errors while debugging and reporting.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;more-usages&#34;&gt;More usages&lt;/h2&gt;
&lt;h4 id=&#34;debugging&#34;&gt;Debugging&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;With database logs find all slow running database queries&lt;/li&gt;
&lt;li&gt;Using Nginx access logs, find slow response pages&lt;/li&gt;
&lt;li&gt;Nginx access logs to generate daily reports for 404s&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;reporting&#34;&gt;Reporting&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;With transaction logs, turn data into knowledge. Generating reports for sales, registrations, popular products added in cart etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;monitoring--alerting&#34;&gt;Monitoring &amp;amp; Alerting&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Email alert setup for jobs&lt;/li&gt;
&lt;li&gt;With logging of server memory, cpu, disk and network utilisation provides server monitoring.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;performance-benchmarking&#34;&gt;Performance Benchmarking&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Daily report for server response time, and when 90 percentile of response time goes higher than 3 seconds send alerts.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;analytics&#34;&gt;Analytics&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Logs collected over years is the biggest data available for analytics. We could also achieve real-time analytics such as most popular products.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And these are just some examples of structured logging usage. However, once infrastructure in place, it is upto us to explore and find more opportunity to leverage it.&lt;/p&gt;
- //www.sunitparekh.in/posts/22-structured-logging/ - 2020 sunitparekh.in</description>
        </item>
    
    
  </channel>
</rss> 