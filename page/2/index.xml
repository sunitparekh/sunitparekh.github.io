<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sUnit Blog</title>
    <link>//www.sunitparekh.in/</link>
    <description>Recent content on sUnit Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>2020 sunitparekh.in</copyright>
    <lastBuildDate>Mon, 08 Mar 2021 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="//www.sunitparekh.in/index.xml" rel="self" type="application/rss+xml" />
    
    
    
        <item>
        <title>Story Mapping, Visual Way of Building Product Backlog</title>
        <link>//www.sunitparekh.in/posts/25-story-mapping/</link>
        <pubDate>Tue, 13 Jan 2015 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/25-story-mapping/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/25-story-mapping/ -&lt;h2 id=&#34;article-is-published-on-thoughtworks-insights-herehttpwwwthoughtworkscominsightsblogstory-mapping-visual-way-building-product-backlog&#34;&gt;Article is published on ThoughtWorks Insights &lt;a href=&#34;http://www.thoughtworks.com/insights/blog/story-mapping-visual-way-building-product-backlog&#34;&gt;here&lt;/a&gt;..&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.thoughtworks.com/insights/blog/story-mapping-visual-way-building-product-backlog&#34;&gt;http://www.thoughtworks.com/insights/blog/story-mapping-visual-way-building-product-backlog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/25/featured.jpg&#34; alt=&#34;Story Map&#34;&gt;&lt;/p&gt;
- //www.sunitparekh.in/posts/25-story-mapping/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>How to begin with Agile and Continuous Delivery on Legacy Projects?</title>
        <link>//www.sunitparekh.in/posts/24-legacy-projects/</link>
        <pubDate>Fri, 31 Oct 2014 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/24-legacy-projects/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/24-legacy-projects/ -&lt;p&gt;In my interactions with people, I hear &amp;ldquo;Agile and Continuous Delivery works for new green field projects, but we have legacy project. We don&amp;rsquo;t know where to start or we can&amp;rsquo;t do agile and continuous delivery on our project&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Most of the time legacy projects are facing typical issues like fragile codebase, too much technical debt, old libraries &amp;amp; frameworks. Which resulting into long development and testing cycles. To solve these problems, team decides to follow Agile practices. Following agile practices requires specialized skills like Continuous Integration, Test Driven Development, Refactoring and Evolutionary Design&amp;hellip; and difficulty is where to start, there are so many agile engineering practices. Should we start Big Bang, stop all development until we have CI, Automated Tests, &amp;hellip; everything in place? My answer is No Big Bang.&lt;/p&gt;
&lt;p&gt;Here is step by step approach that worked for me to move towards CD with agile practices. Remember this is a journey and can take upto months or years to get results, based on size of the project, so have patience.&lt;/p&gt;
&lt;h2 id=&#34;step-1-automated-build-and-deployment&#34;&gt;Step 1: Automated build and deployment&lt;/h2&gt;
&lt;p&gt;On most of the legacy projects I have seen, taking build and performing deployment is quite long process. One of the main reason for long cycle is, build and deployment steps are manual, resulting into long downtime for systems (environments) during deployment. If we notice all the steps we do for building artifacts and performing deployment are repetitive and can be automated using scripts. In case of product we can have automated upgrades for client with proper distribution channel.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools and techniques for automated build&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Packaging application in native format using tools like &lt;a href=&#34;https://github.com/jordansissel/fpm&#34;&gt;FPM&lt;/a&gt; to build RPM, DEB packages to deploy application in native way. For products this approach is ideal and we can leverage system default package manager for automated upgrade. And this is quite common in applications distributions like Apache HTTP Server, JDK etc.&lt;/li&gt;
&lt;li&gt;Use Continuous Integration servers like &lt;a href=&#34;http://www.go.cd/&#34;&gt;Go&lt;/a&gt; to build artifacts and trigger deployment.&lt;/li&gt;
&lt;li&gt;Use &lt;a href=&#34;http://www.getchef.com/chef/&#34;&gt;Chef&lt;/a&gt; to provision servers and deploy applications triggered via downstream pipelines in CI server.&lt;/li&gt;
&lt;li&gt;Use &lt;a href=&#34;http://flywaydb.org/&#34;&gt;Flyway&lt;/a&gt; or &lt;a href=&#34;http://www.liquibase.org/&#34;&gt;Liquibase&lt;/a&gt; for running database migrations in incremental way.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/24/simple-pipeline.svg&#34; alt=&#34;simple deployment pipeline&#34;&gt;&lt;/p&gt;
&lt;p&gt;Next question comes in mind is, what should be the branching strategy? I recommend following 3 active branch strategy.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Master development branch&lt;/strong&gt;, used continuously for active development&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Release Candidate branch&lt;/strong&gt;, is very short lived branch, created as release candidate for production and cut from master. Once deployed to production this becomes the &lt;em&gt;Production branch&lt;/em&gt; This is also known as &lt;strong&gt;beta&lt;/strong&gt; branch.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Production branch&lt;/strong&gt;, used for defect and emergency fixes (hotfix)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/24/3-branch-pipeline.svg&#34; alt=&#34;3 branch deployment pipeline&#34;&gt;&lt;/p&gt;
&lt;p&gt;Doing automated deployment enables us to deploy any build at will even for small bug fix. This enables QA to get latest code for testing anytime as soon as it is checked in by developers. At this step we are still doing manual testing.
{: .clear}&lt;/p&gt;
&lt;h2 id=&#34;step-2-automated-sanity-test-suite&#34;&gt;Step 2: Automated sanity test suite&lt;/h2&gt;
&lt;p&gt;Building full automation suite to get good coverage for CD is long way to go. My suggestion here is to start small, identify blockers or critical end user scenarios and write automated tests just for those. Blocker means if something fails then end user is unable to use application and critical for business to continue. e.g. in retail website, credit card payment not working in purchase workflow. Lets call this test suite as sanity. Remember to keep this as small as possible, I would say this test suite should run in 10 min max.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/24/automated-sanity-test.svg&#34; alt=&#34;automated sanity test&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once the &amp;lsquo;Sanity automated tests&amp;rsquo; are ready, lets put them to run on every check-in using CI setup done before. This provides safety net against critical paths for every check-in done by developer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools and techniques for automated build&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Perform headless website testing using &lt;a href=&#34;http://phantomjs.org/headless-testing.html&#34;&gt;PhantomJS&lt;/a&gt; in combination with &lt;a href=&#34;http://jasmine.github.io/&#34;&gt;Jasmine&lt;/a&gt; and &lt;a href=&#34;https://github.com/airportyh/testem&#34;&gt;Testem&lt;/a&gt;. Other alternatives are &lt;a href=&#34;http://docs.seleniumhq.org/&#34;&gt;Selenium&lt;/a&gt; and &lt;a href=&#34;http://sahi.co.in/sahi-open-source/&#34;&gt;Sahi&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Same Sanity test suite can be run against all environments with different configurations and parameters. This helps in verifying and building confidence in our builds and deployments in each environment.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Evolve automated sanity test suite to achieve acceptance test suite with more End-2-End type of tests. However, please make sure you follow &lt;a href=&#34;http://martinfowler.com/bliki/TestPyramid.html&#34;&gt;Test Pyramid&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-3-development-with-automated-unit-tests-and-refactoring&#34;&gt;Step 3: Development with automated unit tests and refactoring&lt;/h2&gt;
&lt;p&gt;Now the tough one. Big bang unit testing and refactoring is &lt;em&gt;big NO&lt;/em&gt;. You need to be most careful in this part of CD adoption. First step is to define single &lt;a href=&#34;&#34;&gt;Automated Tests Strategy&lt;/a&gt;. Make sure everyone understands &lt;a href=&#34;http://martinfowler.com/bliki/TestPyramid.html&#34;&gt;Test Pyramid&lt;/a&gt; and follows principle of write more unit tests and less acceptance tests. Avoid repeating same tests in different test suites. There is one and only one test stratergy across team, do not fall into trap of different strategy for development team and testing team, remember ONE team.&lt;/p&gt;
&lt;p&gt;I recommend baby steps again here, do refactoring and write unit tests only for features which are under development and touched for enhancement. Do not try to cover non-touched code. In case of Registration feature not changing, do not write unit tests or refactor code related to registration feature.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/24/automated-unit-test.svg&#34; alt=&#34;automated unit test&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Do progressive refactoring and test coverage for code under heavy development, do just enough for others. In short invest more in changing codebase and less in dead code.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;Steps for development,&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write unit test for existing functionality, provide safety net before you make the enhancements. Sometime code is not in a shape of writing unit tests and without refactoring you won&amp;rsquo;t be able to write unit tests. In such cases just do enough refactoring which enables you to write unit tests&lt;/li&gt;
&lt;li&gt;Once you have safety net of automated tests, do heavy refactoring if needed&lt;/li&gt;
&lt;li&gt;Now make enhancements either by following test first or test last approach.&lt;/li&gt;
&lt;li&gt;If needed, do refactoring of the code you just wrote before you call it done.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Watch Martin Flower&amp;rsquo;s &lt;a href=&#34;https://www.youtube.com/watch?v=vqEg37e4Mkw&#34;&gt;Workflow of Refactoring&lt;/a&gt; to learn more.&lt;/p&gt;
&lt;h3 id=&#34;test-last-to-test-first-journey&#34;&gt;Test last to test first journey&lt;/h3&gt;
&lt;p&gt;Lots of time I realise that team is not familiar with the xUnit frameworks and not written any unit tests in past. Have patience, give them space to learn how to write effective unit test, learn good practices and patterns in unit testing. Let them start with test last and slowly move them towards test first journey. Since we are looking at legacy project here we are doing test last anyways. Even if you are following test last, do one change to code and write test, do not wait for everything to finish and then write all tests.&lt;/p&gt;
&lt;h3 id=&#34;three-levels-of-refactoring&#34;&gt;Three levels of refactoring&lt;/h3&gt;
&lt;h4 id=&#34;code-level-refactoring&#34;&gt;Code level refactoring&lt;/h4&gt;
&lt;p&gt;This is first level of refactoring that each and every team member should do ruthlessly. Such as better naming, smaller methods, &amp;hellip; etc&lt;/p&gt;
&lt;h4 id=&#34;design-level-refactoring&#34;&gt;Design level refactoring&lt;/h4&gt;
&lt;p&gt;Team should change design within codebase to apply design patterns wherever necessary to represent code in better way which allows to make future enhancements easily. like removing large if/else and switch/case chain to appropriate design pattern. Make sure we share such refactoring with all developers to have knowledge spread across and learning by examples.&lt;/p&gt;
&lt;h4 id=&#34;architecture-level-refactoring&#34;&gt;Architecture level refactoring&lt;/h4&gt;
&lt;p&gt;Most of the time team ask me, Code and Design level refactoring we are able to do but we find it difficult to go for architecture level refactoring. And this is the most important refactoring to break the ice of legacy code. Most of the time legacy codebase is monolithic in nature and would like to move towards service oriented architecture. How to do it? You can&amp;rsquo;t go back to business and say we are stopping all other development and no release for next 3 months since we are doing architecture refactoring. Here is my way for approaching such refactoring,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Build services as method calls using design level refactoring&lt;/li&gt;
&lt;li&gt;Move method calls to services, however, this services coded and deployed in same monolithic way, make localhost calls&lt;/li&gt;
&lt;li&gt;Move services to separate codebase, but deploy in same monolithic way, make localhost calls&lt;/li&gt;
&lt;li&gt;Move service as separate independent deployment, but deploy on same box, make localhost calls&lt;/li&gt;
&lt;li&gt;Make service totally independent as you would liked it to be, make remote calls&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Above steps can take weeks or months based on the complexity and size. My guideline is to divide into steps that you could complete within one iteration, so that you keep it green and always running.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Above steps can be done simultaneously without any restrictions. This is just a guideline and feel free to try different approaches that works for you and your team.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;support-needed-during-cd-journey&#34;&gt;Support needed during CD journey&lt;/h2&gt;
&lt;p&gt;During the agile adoption journey it is important that team gets required support in terms of,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Team needs necessary initial training and coaching on Agile practices like Continuous Integration, Test Driven Development, Refactoring and Evolutionary Design&amp;hellip;&lt;/li&gt;
&lt;li&gt;Have a coach, internal or external, who mentors team on Agile adoption journey. It is important that someone constantly looking at how are team is progressing on CD journey? Is team getting benefits? Is team getting enough support to adopt new way of development?&lt;/li&gt;
&lt;li&gt;All stakeholder needs to understand that during this journey initially when team is learning, refactoring &amp;amp; building automated test suites, it might take little longer to deliver. However after sometime trend should shift and start showing benefits with quicker &amp;amp; quality deliveries.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Run regular retrospective on Agile adoption and CD progress as health check.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Please share your experience with Agile adoption on legacy project and challenges faced using comments.&lt;/p&gt;
- //www.sunitparekh.in/posts/24-legacy-projects/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Building a Two-Stack CMS for a global product catalog</title>
        <link>//www.sunitparekh.in/posts/23-two-stack-cms/</link>
        <pubDate>Mon, 06 Oct 2014 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/23-two-stack-cms/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/23-two-stack-cms/ -&lt;h2 id=&#34;article-is-published-on-martinfowlercom-as-infodeck-herehttpmartinfowlercomarticlestwo-stack-cms&#34;&gt;Article is published on MartinFowler.com as InfoDeck &lt;a href=&#34;http://martinfowler.com/articles/two-stack-cms/&#34;&gt;here&lt;/a&gt;..&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://martinfowler.com/articles/two-stack-cms/&#34;&gt;http://martinfowler.com/articles/two-stack-cms/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/23/two-stack-cms.svg&#34; alt=&#34;Two Stack CMS&#34;&gt;&lt;/p&gt;
- //www.sunitparekh.in/posts/23-two-stack-cms/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Use structured logging for log search and analytics</title>
        <link>//www.sunitparekh.in/posts/22-structured-logging/</link>
        <pubDate>Sat, 06 Sep 2014 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/22-structured-logging/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/22-structured-logging/ -&lt;p&gt;Logging is followed in almost every project. However, most of the time we end up using logs only for debugging and auditing purpose. Since past few projects we have been exploring more opportunities for leveraging logs for purposes like application metrics collection, reporting, monitoring and alerting. And during this, I learnt about structured logging and how it enables us to achieve lot more using logs.&lt;/p&gt;
&lt;p&gt;Lets first look at what we need to follow while logging to achieve structured logging.&lt;/p&gt;
&lt;h2 id=&#34;what-is-structured-logging&#34;&gt;What is structured logging?&lt;/h2&gt;
&lt;p&gt;Not only log level is important, but what we log &amp;amp; how we log also matters. Lets look at the default log message format,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-log&#34; data-lang=&#34;log&#34;&gt;127.0.0.1 [2014-07-22T18:12:27.200+0530] &amp;quot;GET /api/modules/doc_id/navigation HTTP/1.1&amp;quot; 200 476
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Above message is interpreted well by humans since we know, &lt;code&gt;120.0.0.1&lt;/code&gt; is IP, &lt;code&gt;2014-07-22T18:12:27.200+0530&lt;/code&gt; is timestamp, &lt;code&gt;GET&lt;/code&gt; is request methods, &lt;code&gt;200&lt;/code&gt; is response status and &lt;code&gt;476&lt;/code&gt; is server response time. And such interpretation is required for each message logging.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s provide structure to the above log message,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-log&#34; data-lang=&#34;log&#34;&gt;ip=&amp;quot;127.0.0.1&amp;quot; timestamp=&amp;quot;2014-07-22T18:12:27.200+0530&amp;quot; method=GET
url=&amp;quot;/api/modules/doc_id/navigation&amp;quot; protocol=HTTP/1.1 status=200 responseTime=476
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Above structured message is self explanatory and easy to parse and index by system. This technique of &lt;code&gt;key=value&lt;/code&gt; style logging is also known as logging with context. Using above log message keys we can find all slow pages, by querying logs with &lt;code&gt;status = 200&lt;/code&gt; and &lt;code&gt;responseTime &amp;gt; 2000&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now lets take some examples of structured logs to understand it usage better.&lt;/p&gt;
&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;
&lt;h4 id=&#34;background-job-logs&#34;&gt;Background job logs&lt;/h4&gt;
&lt;p&gt;Most of the application now days have have background jobs running at regular interval. With following structured logging for each jobs,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-log&#34; data-lang=&#34;log&#34;&gt;timestamp=&amp;quot;2014-07-22T18:12:27.200+0530&amp;quot; host=server20  tag=jobserver jobName=image_upload
jobStartTime=&amp;quot;2014-07-22T18:10:00.100+0530&amp;quot; jobEndTime=&amp;quot;2014-07-22T18:12:27.100+0530&amp;quot;
jobExecutionTime=9840 jobStatus=success noOfImageUploaded=125
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;following can be achieved,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get alert message when jobStatus is failure, we do&lt;/li&gt;
&lt;li&gt;Monitor average job execution time and we have setup for each job if it reaches more than average sends alert.&lt;/li&gt;
&lt;li&gt;Monitoring average response time also helps in tuning the frequency of the job runs.&lt;/li&gt;
&lt;li&gt;To analyze random failure or slowness in jobs, information in log is really useful to find if it is failing on specific hosts or at specific time or when run in parallel with any other jobs or no of items are too many to process etc.&lt;/li&gt;
&lt;li&gt;Using more meta info like noOfImageUpload and jobExecutionTime we can calculate average time for each image upload.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;distributed-correlated-logs&#34;&gt;Distributed correlated logs&lt;/h4&gt;
&lt;p&gt;With distributed and microservice architecture, it is quite natural to have logs spread across systems. With structure logs and using common transaction id shared across systems, we can correlate logs and turn logs into information used for debugging, auditing, reporting and monitoring.&lt;/p&gt;
&lt;p&gt;Lets take the example of order request after successful payment.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-log&#34; data-lang=&#34;log&#34;&gt;timestamp=&amp;quot;2014-07-22T18:12:27.100+0530&amp;quot; host=server01 tag=webServer
transactionId=458748939 cientIP=83.84.85.86 sessionId=123456789
message=&amp;quot;Order confirmation request received&amp;quot;

timestamp=&amp;quot;2014-07-22T18:12:27.200+0530&amp;quot; host=server03 tag=orderService
transactionId=458748939 message=&amp;quot;Order created&amp;quot;
orderAmount=550

timestamp=&amp;quot;2014-07-22T18:12:27.250+0530&amp;quot; host=server03 tag=inventoryService
transactionId=458748939 message=&amp;quot;Online inventory updated&amp;quot;

timestamp=&amp;quot;2014-07-22T18:12:27.300+0530&amp;quot; host=server07 tag=paymentService
transactionId=458748939 message=&amp;quot;Payment details stored against order.&amp;quot;
paymentMode=CreditCard

timestamp=&amp;quot;2014-07-22T18:12:27.350+0530&amp;quot; host=server05  tag=couponService
transactionId=458748939 message=&amp;quot;Redeem coupon ABCDE marked for user.&amp;quot;
couponType=REWARD couponCode=ABCDE

timestamp=&amp;quot;2014-07-22T18:12:27.400+0530&amp;quot; host=server01 tag=webServer
transactionId=458748939 message=&amp;quot;Request completed&amp;quot;

timestamp=&amp;quot;2014-07-22T18:12:28.500+0530&amp;quot; host=server06  tag=emailService
transactionId=458748939 message=&amp;quot;Order email sent&amp;quot;

timestamp=&amp;quot;2014-07-22T18:12:27.450+0530&amp;quot; host=server05  tag=rewardService
transactionId=458748939 message=&amp;quot;Reward points updated.&amp;quot;

timestamp=&amp;quot;2014-07-22T18:15:00.100+0530&amp;quot; host=server25  tag=shippingService
transactionId=458748939 message=&amp;quot;Order received by shipment system.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;with above messages we can,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We are better equipped with debugging issues across systems including async steps of the transaction. Using transactionId we can connect logs and findout client/user specific details and track incident.  e.g. track couponCode used by user with connecting logs from couponService to webServer&lt;/li&gt;
&lt;li&gt;Using paymentMode, we can learn more about what kind of payment modes are preferred by customers.&lt;/li&gt;
&lt;li&gt;Calculate average response time in processing order request.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Leverage apache &lt;code&gt;mod_unique_id&lt;/code&gt; module to generate transaction id at web server and later share it with other services by passing it in request headers.&lt;/p&gt;
&lt;h2 id=&#34;tools&#34;&gt;Tools&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.splunk.com/&#34;&gt;Splunk&lt;/a&gt;, is best in class, commercial product. We are using it in production for large system generating more than 100GB of logs per day. Splunk would be my personal recommendation as well. Lets take example and learn more about using Splunk.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lets find 404s on website using Splunk&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/22/splunk-query.png&#34; alt=&#34;splunk query for finding 404&#34;&gt;&lt;/p&gt;
&lt;p&gt;Query: &lt;code&gt;tag=production sourcetype=nginx-access GET 404 | rex &amp;quot;\&amp;quot;GET (?&amp;lt;url&amp;gt;\S*) &amp;quot; | stats count by url | sort -count | head 20&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Lets understand query in detail. Splunk support &lt;a href=&#34;http://martinfowler.com/articles/collection-pipeline/&#34;&gt;unix style pipes in query&lt;/a&gt;, so you could pass output of one command to another and build on. In above example we used 5 different commands,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;tag=production&lt;/code&gt; and &lt;code&gt;sourcetype=nginx-access&lt;/code&gt; with &lt;code&gt;GET 404&lt;/code&gt; returns all 404 log statements from all productions servers and source file name nginx-access&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rex &amp;quot;\&amp;quot;GET (?&amp;lt;url&amp;gt;\S*) &amp;quot;&lt;/code&gt; extract URL from the log using reg-ex&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stats count&lt;/code&gt; by url group and count by url&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sort -count&lt;/code&gt; sort in descending order on count&lt;/li&gt;
&lt;li&gt;&lt;code&gt;head 20&lt;/code&gt; take first 20 from the result set&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://logentries.com/&#34;&gt;LogEntries&lt;/a&gt; is another feature rich SaaS solution on cloud. Other options are &lt;a href=&#34;https://www.loggly.com/&#34;&gt;Loogly&lt;/a&gt;, &lt;a href=&#34;https://papertrailapp.com/&#34;&gt;PaperTrail&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.elasticsearch.org/overview/logstash/&#34;&gt;LogStash&lt;/a&gt; + &lt;a href=&#34;http://www.elasticsearch.org/overview/elasticsearch/&#34;&gt;Elasticsearch&lt;/a&gt; + &lt;a href=&#34;http://www.elasticsearch.org/overview/kibana/&#34;&gt;Kibana&lt;/a&gt; combination is best open-source one in this space.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://graylog2.org/&#34;&gt;GrayLog2&lt;/a&gt;, open-source log analytics solutions. Used with syslog to aggregate logs.&lt;/p&gt;
&lt;p&gt;Even though structured logging is quite useful on individual system. However until we have logs from all the system collected and indexed together, power of structured logging is under utilized. So lets look at what are different ways we can aggregate logs from multiple systems.&lt;/p&gt;
&lt;h2 id=&#34;how-to-aggregate-logs&#34;&gt;How to aggregate logs?&lt;/h2&gt;
&lt;p&gt;There are multiple approaches available for log aggregation.&lt;/p&gt;
&lt;h4 id=&#34;log-file-replication&#34;&gt;Log File Replication&lt;/h4&gt;
&lt;p&gt;Simplest one is, continue logging to file system on application server and set up an independent process to monitor files and send logs to central log server every &amp;lsquo;n&amp;rsquo; milliseconds.&lt;/p&gt;
&lt;h4 id=&#34;syslog&#34;&gt;Syslog&lt;/h4&gt;
&lt;p&gt;To achieve real time monitoring and alerting we can use syslog approach, directly feeding logs to a central log server. Syslog is available by default on most of the linux machines. &lt;a href=&#34;http://www.rsyslog.com/&#34;&gt;rsyslog&lt;/a&gt; or &lt;a href=&#34;http://www.balabit.com/network-security/syslog-ng/opensource-logging-system/&#34;&gt;syslog-ng&lt;/a&gt; are two popular syslog implementations.&lt;/p&gt;
&lt;h4 id=&#34;agents&#34;&gt;Agents&lt;/h4&gt;
&lt;p&gt;Most of the products in this space provide their own agents, which runs on client and sends logs real-time to central log server. e.g. &lt;a href=&#34;http://wiki.splunk.com/Community:Getting_data_into_Splunk&#34;&gt;Splunk&lt;/a&gt;, &lt;a href=&#34;https://logentries.com/doc/forwarders/&#34;&gt;LogEntries&lt;/a&gt; etc. There are specific tools available just for aggregation purposes like &lt;a href=&#34;http://flume.apache.org/&#34;&gt;Apache Flume&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/22/centralised-logging.svg&#34; alt=&#34;centralised aggregated logs&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In distributed systems it is important that we have realtime log aggregation setup. And it is equally important that time on all application servers is in sync. Since a millisecond differences can have unordered logs and leads to confusion and errors while debugging and reporting.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;more-usages&#34;&gt;More usages&lt;/h2&gt;
&lt;h4 id=&#34;debugging&#34;&gt;Debugging&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;With database logs find all slow running database queries&lt;/li&gt;
&lt;li&gt;Using Nginx access logs, find slow response pages&lt;/li&gt;
&lt;li&gt;Nginx access logs to generate daily reports for 404s&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;reporting&#34;&gt;Reporting&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;With transaction logs, turn data into knowledge. Generating reports for sales, registrations, popular products added in cart etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;monitoring--alerting&#34;&gt;Monitoring &amp;amp; Alerting&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Email alert setup for jobs&lt;/li&gt;
&lt;li&gt;With logging of server memory, cpu, disk and network utilisation provides server monitoring.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;performance-benchmarking&#34;&gt;Performance Benchmarking&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Daily report for server response time, and when 90 percentile of response time goes higher than 3 seconds send alerts.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;analytics&#34;&gt;Analytics&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Logs collected over years is the biggest data available for analytics. We could also achieve real-time analytics such as most popular products.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And these are just some examples of structured logging usage. However, once infrastructure in place, it is upto us to explore and find more opportunity to leverage it.&lt;/p&gt;
- //www.sunitparekh.in/posts/22-structured-logging/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Guidelines for Structuring Automated Tests</title>
        <link>//www.sunitparekh.in/posts/21-automated-tests/</link>
        <pubDate>Tue, 22 Jul 2014 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/21-automated-tests/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/21-automated-tests/ -&lt;h2 id=&#34;article-is-published-on-thoughtworks-insights-herehttpwwwthoughtworkscominsightsblogguidelines-structuring-automated-tests&#34;&gt;Article is published on ThoughtWorks Insights &lt;a href=&#34;http://www.thoughtworks.com/insights/blog/guidelines-structuring-automated-tests&#34;&gt;here&lt;/a&gt;..&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.thoughtworks.com/insights/blog/guidelines-structuring-automated-tests&#34;&gt;http://www.thoughtworks.com/insights/blog/guidelines-structuring-automated-tests&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/21/featured.svg&#34; alt=&#34;Automated Tests&#34;&gt;&lt;/p&gt;
- //www.sunitparekh.in/posts/21-automated-tests/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Using TDD to Influence Design</title>
        <link>//www.sunitparekh.in/posts/20-tdd-influence-design/</link>
        <pubDate>Fri, 06 Jun 2014 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/20-tdd-influence-design/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/20-tdd-influence-design/ -&lt;h2 id=&#34;article-is-published-on-thoughtworks-insights-herehttpwwwthoughtworkscominsightsblogusing-tdd-influence-design&#34;&gt;Article is published on ThoughtWorks Insights &lt;a href=&#34;http://www.thoughtworks.com/insights/blog/using-tdd-influence-design&#34;&gt;here&lt;/a&gt;..&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.thoughtworks.com/insights/blog/using-tdd-influence-design&#34;&gt;http://www.thoughtworks.com/insights/blog/using-tdd-influence-design&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/20/tdd.png&#34; alt=&#34;TDD&#34;&gt;&lt;/p&gt;
- //www.sunitparekh.in/posts/20-tdd-influence-design/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Zero downtime using blue-green deployment strategy</title>
        <link>//www.sunitparekh.in/posts/19-blue-green-deployment/</link>
        <pubDate>Wed, 23 Oct 2013 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/19-blue-green-deployment/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/19-blue-green-deployment/ -&lt;p&gt;Zero downtime during application deployment is one of the key requirements for continuos delivery. And no business would like their site to be down and showing maintenance page every few days/weeks during deployment.&lt;/p&gt;
&lt;p&gt;To achieve this we decide to go for &lt;a href=&#34;http://martinfowler.com/bliki/BlueGreenDeployment.html&#34;&gt;blue-green deployment&lt;/a&gt;. However, we were challenged with how to do this in legacy style data center infrastructure where we are,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Not able to spin new machines and throw away old machines automatically using scripts&lt;/li&gt;
&lt;li&gt;Don&amp;rsquo;t have ability to add/remove instances using scripts from load-balancer&lt;/li&gt;
&lt;li&gt;Network level configurations are done manually like firewall setting&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Also keeping full in-active stack didn&amp;rsquo;t sound good idea. Now we had to made some modifications to achieve zero downtime using blue-green deployment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Decision 1:&lt;/strong&gt; We took out database from the application deployment stack. Since we were using NoSQL MongoDB database, it didn&amp;rsquo;t require any schema migration etc. However, we required to follow design principle, always write code which is backward compatible with the data models. And if there is any data migration required it should be run after deployment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Decision 2:&lt;/strong&gt; Use RPM to package apps and run like a service to start and stop. This enabled us to deploy application easily with the standard chef recipes. All application components are packaged as RPMs and published to repository from CI pipeline. Standardise deployment process across all components/application. We used FPM gem to build RPMs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Decision 3:&lt;/strong&gt; All application/component should provide 2 state heartbeat, live or standby, with ability to change the current state of the heartbeat at runtime using api call. Configure one load-balance to listen to live heartbeat and another to standby. Allows to add/remove instances from load-balancer by changing heartbeat state.&lt;/p&gt;
&lt;p&gt;And with above changes the deployment steps are,&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/19/1-state-before-deployment.svg&#34; alt=&#34;Pre deployment state&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Change heartbeat of the green stack to state &amp;lsquo;standby&amp;rsquo;. This will remove green stack from LIVE load-balancer pool and no new request send to green stack.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/19/2-green-standby.svg&#34; alt=&#34;Change heartbeat of the green stack&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Deploy latest version of the application to green stack. Wait sometime to complete the inflight request on green stack before deployment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/19/3-green-v2.svg&#34; alt=&#34;Deploy latest version to green stack&#34; title=&#34;Deploy latest version to green stack&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Sanity test green stack using standby load-balancer. Ideally automated, this will make sure deployment is good.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 4:&lt;/strong&gt; Revert heartbeat of the green stack to state &amp;lsquo;live&amp;rsquo;. This will put the green stack back to LIVE load-balancer pool.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/19/4-green-v2-live.svg&#34; alt=&#34;Revert heartbeat of the green stack to state &amp;lsquo;live&amp;rsquo;&#34; title=&#34;Revert heartbeat of the green stack to state &#39;live&#39;&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you notice the blue stack running on v1 and green stack running on v2. And both the stacks are connected to same database. Which means v2 codebase should work with old data models. And if there is any database migration should be carried only after all stack upgraded to latest version.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 5:&lt;/strong&gt; Repeat above steps for blue stack,&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/19/5-blue-standby.svg&#34; alt=&#34;Change heartbeat of the blue stack&#34; title=&#34;Change heartbeat of the blue stack&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/19/6-blue-v2.svg&#34; alt=&#34;Deploy latest version to blue stack&#34; title=&#34;Deploy latest version to blue stack&#34;&gt;&lt;/p&gt;
&lt;p&gt;And finally v2 deployed fully,&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/19/7-blue-v2-live.svg&#34; alt=&#34;latest version deployed on all stacks&#34; title=&#34;latest version deployed on all stacks&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 6:&lt;/strong&gt; Optional, run database migration (independent of the deployment)&lt;/p&gt;
&lt;p&gt;What we achieved is, at any give point of time either blue or green stack is actively servicing the requests without downtime.&lt;/p&gt;
&lt;p&gt;However, the one point to note here is that during deployment only half capacity available, which means deployment should be avoided at peak load time.&lt;/p&gt;
- //www.sunitparekh.in/posts/19-blue-green-deployment/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Building highly scalable and performance application using non-blocking architecture</title>
        <link>//www.sunitparekh.in/posts/18-non-blocking/</link>
        <pubDate>Tue, 07 May 2013 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/18-non-blocking/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/18-non-blocking/ -&lt;p&gt;I have been working on web application development since last 12+ years and had privileged to work on more than 20+ different project. Now days the expectations from web apps are totally different than it was few years back. End users are provided with rich content on single page (Amazon, CNN, &amp;hellip;). On a single page, lots of data needs to be mashed up and data may come from different sources.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/18/1-website-screenshots.jpg&#34; alt=&#34;Websites with data mashup&#34;&gt;&lt;/p&gt;
&lt;p&gt;We know how to put together the N-tier architecture.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/18/2-service-oriented-architecture.svg&#34; alt=&#34;Service oriented architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;And the request workflow will be as following,&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/18/3-request-workflow.png&#34; alt=&#34;Request workflow&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now if we notice the above workflow, it is sequential and most of the time thread on web server and app server spend is waiting for response form app server and database respectively rather than doing some meaningful work (processing). This is what is called BLOCKING. Lets take same example and try to draw web server thread timeline.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/18/4-sequencial-timeline.jpg&#34; alt=&#34;Sequential workflow timeline&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/18/5-legends.jpg&#34; alt=&#34;timeline legends&#34;&gt;&lt;/p&gt;
&lt;p&gt;RED is time spend by thread waiting for response/result from app server. And GREEN is the time spend doing some meaningful processing by web server. In above example it was total 10 sec response time and 1 thread involved in processing. Lets assume that above 3 calls to app server can be parallelise to optimise response time to end user.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/18/6-standard-parallel-processing.jpg&#34; alt=&#34;Standard parallel processing&#34;&gt;&lt;/p&gt;
&lt;p&gt;In parallel processing the response time was reduced to 7 sec. However, total 4 threads participated in processing and in total 13 sec of thread time it took. Again here also the processing was BLOCKING. Which means parallel processing provides better performance in terms of response time, but required more resources to process the request.&lt;/p&gt;
&lt;p&gt;What we need is parallel processing with non-blocking threads. Means when the thread is waiting for the response from other systems, it should be made available to do some other meaningful work. Something like following,&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/18/7-non-blocking-execution.jpg&#34; alt=&#34;Non blocking execution timeline&#34;&gt;&lt;/p&gt;
&lt;p&gt;If we can achieve non-blocking architecture than the response time goes down to as low as 5 sec. And also consumes less thread resources. Now the question is how I can achieve this? In today&amp;rsquo;s polygot programming world, we have plenty of alternatives available.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/18/8-tech-options.jpg&#34; alt=&#34;Non blocking technical options&#34;&gt;&lt;/p&gt;
&lt;p&gt;Non-blocking is not new, Nginx is event based and uses similar principle, Messsage based architecture is another classical example to solve similar problems, however that brings in asynchronous complexity.  MongoDB and similar polygot persistence works on same principles and provides eventual consistency.&lt;/p&gt;
&lt;p&gt;I recommend trying out following technology/framework choices to achieve non-blocking architecture,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;http://nodejs.org/&#34;&gt;NodeJS&lt;/a&gt;&lt;/strong&gt;, this is the most popular choice so far in today&amp;rsquo;s technology choices. And Passanger can provide NodeJS cluster running multiple process on one machine. However, programming in NodeJS is all about callbacks. And lots of OO programmers don&amp;rsquo;t like it. There are plenty of frameworks in NodeJS for web application, the popular ones are is &lt;a href=&#34;http://expressjs.com/&#34;&gt;express.js&lt;/a&gt;, &lt;a href=&#34;http://meteor.com/&#34;&gt;meteor&lt;/a&gt; &amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;http://www.playframework.com/&#34;&gt;Play Framework&lt;/a&gt;&lt;/strong&gt;, this is Scala based web application framework. Framework is very mature and easy to adpat for Java shop organisations. It uses internally Netty, Scala and Akka and provides very nice abstracts to avoids callbacks hell. Based on Scala means love for OO programmers as well. Akka can also be used independently.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; Consider non-blocking architecture when your application have blocking calls and wait times. If your application has more about computation/processing and less or negligible blocking/waiting time the above architecture pattern may not provide better or favorable results.&lt;/p&gt;
- //www.sunitparekh.in/posts/18-non-blocking/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Cross functional requirements</title>
        <link>//www.sunitparekh.in/posts/17-xfr/</link>
        <pubDate>Sat, 04 May 2013 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/17-xfr/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/17-xfr/ -&lt;p&gt;It&amp;rsquo;s always been difficult to identify and easy to miss-out on creating stories for cross functional requirement (XFR) a.k.a NonFunctional requirements (NFR) during inception. Inception is a short, time boxed, 2-3 weeks initial requirement gathering phase of the software development project lifecycle. I have been to multiple inception and figured out a nice and collaborating way of capturing and converting cross functional requirements into stories. We run it like a workshops, collaborating with client to identify and capture XFRs.&lt;/p&gt;
&lt;p&gt;After understanding and going to functional requirement, plan for XFR session with all the members of the team including stakeholders. We have list of XFRs printed on the cards at ThoughtWorks similar to the one shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/17/cross-functional-requirements.png&#34; alt=&#34;cross functional bilities&#34;&gt;&lt;/p&gt;
&lt;p&gt;There are around 35+ such &amp;ldquo;bility&amp;rdquo; that need to be discussed. During the session we take one &amp;lsquo;bility&amp;rsquo; at a time and not down on stickies what are the requirements related to that &amp;lsquo;bility&amp;rsquo;. It is important to discuss each and every &amp;lsquo;bility&amp;rsquo; and there is a possibility few are not application to the project we are working on. Mark them as NA.&lt;/p&gt;
&lt;p&gt;Once all the &amp;lsquo;bility&amp;rsquo; is discussed break out in small team, discuss each XFR requirements and convert them into stories.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/17/cards-wall.jpg&#34; alt=&#34;cross functional requirement wall&#34;&gt;&lt;/p&gt;
&lt;p&gt;After creating the story list of XFRs, treat them as other stories. Combine the backlog of functional and XFR stories, estimate and prioritise stories together.&lt;/p&gt;
&lt;p&gt;As documentation,  I like to use mind map since it fits that format nicely. Please have a look at the one displayed below for your reference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/17/mind-map.png&#34; alt=&#34;cross functional requirement mindmap&#34;&gt;&lt;/p&gt;
&lt;p&gt;I like calling NFRs as cross functional requirements (XFR) rather than non-functional, since most of the non-functional requirements are kind of indirect functional requirements. e.g. page load time for end user is performance requirement which indirectly related to better user experience.&lt;/p&gt;
- //www.sunitparekh.in/posts/17-xfr/ - 2020 sunitparekh.in</description>
        </item>
    
    
    
        <item>
        <title>Why responsive web design?</title>
        <link>//www.sunitparekh.in/posts/16-responsive-design/</link>
        <pubDate>Tue, 12 Feb 2013 00:00:00 +0000</pubDate>
        
        <guid>//www.sunitparekh.in/posts/16-responsive-design/</guid>
        <description>sUnit Blog //www.sunitparekh.in/posts/16-responsive-design/ -&lt;p&gt;Lots of time when I discuss Responsive Web Design (RWD), sometime I find out that we don&amp;rsquo;t know the problem, we are trying to solve with RWD. And the objective of this blog post is look into the history and learn what problem we try to solve with RWD.&lt;/p&gt;
&lt;p&gt;The multiple screen resolution problem is not new, even in old days the monitors had  different screen resolution. The problem exist from old days. In first attempt we solved multiple screen resolution problem with Fixed Width web page design (Fixed Width Layout Approach).  960px based fixed width design were very common for websites. One of the most popular CSS framework with fixed width was blueprint. The problem with fixed-width layout is white (empty) space on side of the screens. Designer also used that space by having creative backgrounds for the page.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/16/cricinfo-white-space.png&#34; alt=&#34;Cricinfo fix-width web pages&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/16/apple-with-white-space.png&#34; alt=&#34;Apple fix-width web pages&#34;&gt;&lt;/p&gt;
&lt;p&gt;The multiple screen resolution problem didn&amp;rsquo;t go away, after smartphones and tablets the problem became more prominent. In second attempt to solve the problem, used multiple templates for different devices on server side (Seperate Mobile Website Approach). The downside of using the server side device specific templating is that, HTTP caching can&amp;rsquo;t be done. Which is non-negociable for scalability, and to overcome caching issues, on first request the application server recognises the browser agent and redirects the site to device specific page like &lt;a href=&#34;http://www.cricinfo.com&#34;&gt;www.cricinfo.com&lt;/a&gt; or m.cricinfo.com By using different sites/urls for different devices  HTTP caching problem was solved.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/16/cricinfo-white-space.png&#34; alt=&#34;Cricinfo fix-width web pages&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/16/cricinfo-mobile-redirect.png&#34; alt=&#34;Cricinfo mobile redirect web page&#34;&gt;&lt;/p&gt;
&lt;p&gt;Try visiting page: &lt;a href=&#34;http://www.guardian.com&#34;&gt;guardian.com&lt;/a&gt; and &lt;a href=&#34;http://www.cricinfo.com&#34;&gt;cricinfo.com&lt;/a&gt; on mobile device and notice the redirect.&lt;/p&gt;
&lt;p&gt;Now the problem started with maintaining multiple sites/applications. Use experience was not consistent across devices. It was very difficult to keep the feature parity across the device specific sites. Application development, maintenance &amp;amp; production cost &amp;amp; effort increased significantly.&lt;/p&gt;
&lt;p&gt;During same time period people realised that we are wasting so much screen real estate by doing the fixed grid layout, and the &lt;a href=&#34;http://fluidgrids.com/&#34;&gt;fluid grid&lt;/a&gt; layout design started becoming popular for desktops.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/16/fluid-grid-layout.png&#34; alt=&#34;Fluid grid desktop web page&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/16/fluid-grid-layout-mobile.png&#34; alt=&#34;Fluid grid mobile web page&#34;&gt;&lt;/p&gt;
&lt;p&gt;However, fluid grid system depends heavily on browser support and performance. Making it old browser compatible was a big task.&lt;/p&gt;
&lt;p&gt;The latest attempt of providing best viewing experience on all devices &amp;amp; screen resolution at client side (browsers) is known as Responsive Web Design.  With frameworks like &lt;a href=&#34;http://twitter.github.com/bootstrap/&#34;&gt;Twitter Bootstrap&lt;/a&gt;,  it has become easy to get started learning and using Responsive Web Design concept.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/16/bootstrap-desktop.png&#34; alt=&#34;Bootstrap desktop web page&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;//www.sunitparekh.in/images/16/bootstrap-mobile.png&#34; alt=&#34;Bootstrap mobile web page&#34;&gt;&lt;/p&gt;
&lt;p&gt;Notice menu, text, links and buttons in above two screenshots. Same site visited in desktop browser and mobile browser.&lt;/p&gt;
&lt;p&gt;To achieve HTTP caching it was very important that all this dynamic behaviour to be kept on client side, so server has to render the same page for all devices irrespective of the screen sizes and resolutions. With this approach HTTP caching CDN/Reverse proxy can be leveraged agin to achieve high scalability.&lt;/p&gt;
&lt;p&gt;Be aware when using Responsive Web Design,
Works best with latest browsers and high end smartphones, Since RWD relies heavily on client side optimisation and adoption, client needs be powerful.
Slow internet connection speed will give bad user experience since it might take very long to load page. Since all content irrespective of the device is transferred to client. Sometime multiple variations are kept like Menu and the overall web page size increases. Specially for mobile the page size might be very large. Checkout the &lt;a href=&#34;https://github.com/twitter/bootstrap&#34;&gt;size of twitter bootstrap&lt;/a&gt;.&lt;/p&gt;
- //www.sunitparekh.in/posts/16-responsive-design/ - 2020 sunitparekh.in</description>
        </item>
    
    
  </channel>
</rss> 